{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_vggface\n",
      "  Downloading https://files.pythonhosted.org/packages/11/9c/d249cf4998344806d71b0351db690917413d1f7eaab83805f4095375e7a1/keras_vggface-0.5.tar.gz\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/site-packages (from keras_vggface) (1.15.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/site-packages (from keras_vggface) (1.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from keras_vggface) (2.8.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/site-packages (from keras_vggface) (5.2.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/site-packages (from keras_vggface) (1.8.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/site-packages (from keras_vggface) (2.1.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/site-packages (from keras_vggface) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from keras_vggface) (3.13)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (0.7.1)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (1.8.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (3.6.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (1.14.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (0.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow->keras_vggface) (0.31.1)\n",
      "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->keras_vggface) (1.5.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->keras_vggface) (0.14.1)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->keras_vggface) (0.9999999)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->keras_vggface) (2.6.11)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow->keras_vggface) (40.2.0)\n",
      "Building wheels for collected packages: keras-vggface\n",
      "  Running setup.py bdist_wheel for keras-vggface ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/72/aa/01/eb7baeb2f6e2d2f0d2aabddb5f01d57fa22fbd019ee2799bf5\n",
      "Successfully built keras-vggface\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 2.2.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-vggface\n",
      "Successfully installed keras-vggface-0.5\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get images\n",
    "X = []\n",
    "for filename in os.listdir('/input/Train/'):\n",
    "    if filename != 'Thumbs.db':\n",
    "        X.append(img_to_array(load_img('/input/Train/'+filename)))\n",
    "X = np.array(X, dtype=float)\n",
    "Xtrain = 1.0/255*X\n",
    "\n",
    "\n",
    "#Load weights\n",
    "#inception = InceptionResNetV2(weights='imagenet', include_top=True)\n",
    "#inception.graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_vggface import utils\n",
    "\n",
    "# tensorflow\n",
    "vgg_face_model = VGGFace(include_top=True, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[[\"b'Mary_Kay_Place'\", 0.07033763], [\"b'Juliet_Stevenson'\", 0.046592996], [\"b'Imelda_Staunton'\", 0.027502062], [\"b'Ruta_Lee'\", 0.02171729], [\"b'Adrianne_Curry'\", 0.021684552]]]\n"
     ]
    }
   ],
   "source": [
    "# Change the image path with yours.\n",
    "img = image.load_img('/input/Test/2004.jpg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "preds = vgg_face_model.predict(x)\n",
    "#print(preds)\n",
    "print('Predicted:', utils.decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vgg_face_model.graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'predictions/Softmax:0' shape=(?, 1000) dtype=float32>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'fc8/softmax_4/Softmax:0' shape=(?, 2622) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(vgg_face_model.outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
      "58916864/58909280 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_stack(data, filters, s):\n",
    "        output = Conv2D(filters, (3, 3), strides=s, activation='relu', padding='same')(data)\n",
    "        output = BatchNormalization()(output)\n",
    "        return output\n",
    "\n",
    "embed_input = Input(shape=(2622,))\n",
    "\n",
    "#Encoder\n",
    "encoder_input = Input(shape=(256, 256, 1,))\n",
    "encoder_output = conv_stack(encoder_input, 64, 2)\n",
    "encoder_output = conv_stack(encoder_output, 128, 2)\n",
    "encoder_output = conv_stack(encoder_output, 256, 2)\n",
    "encoder_output = conv_stack(encoder_output, 512, 1)\n",
    "encoder_output = conv_stack(encoder_output, 256, 1)\n",
    "\n",
    "#Fusion\n",
    "# y_mid: (None, 256, 28, 28)\n",
    "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
    "fusion_output = Permute((2, 1))(fusion_output) \n",
    "fusion_output = Reshape(([32, 32, 2622]))(fusion_output)\n",
    "fusion_output = concatenate([fusion_output, encoder_output], axis=3) \n",
    "fusion_output = Conv2D(256, (1, 1), activation='relu')(fusion_output) \n",
    "\n",
    "#Decoder\n",
    "decoder_output = UpSampling2D((2, 2))(fusion_output)\n",
    "decoder_output = conv_stack(decoder_output, 128, 1)\n",
    "decoder_output = conv_stack(decoder_output, 64, 1)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = conv_stack(decoder_output, 32, 1)\n",
    "decoder_output = conv_stack(decoder_output, 16, 1)\n",
    "decoder_output = Conv2D(2, (2, 2), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 187s 5s/step - loss: 0.0434\n",
      "Epoch 2/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0114\n",
      "Epoch 3/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0108\n",
      "Epoch 4/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0106\n",
      "Epoch 5/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0104\n",
      "Epoch 6/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0102\n",
      "Epoch 7/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0102\n",
      "Epoch 8/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0100\n",
      "Epoch 9/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0101\n",
      "Epoch 10/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0099\n",
      "Epoch 11/22\n",
      "40/40 [==============================] - 176s 4s/step - loss: 0.0099\n",
      "Epoch 12/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0098\n",
      "Epoch 13/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0098\n",
      "Epoch 14/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0099\n",
      "Epoch 15/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0098\n",
      "Epoch 16/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0098\n",
      "Epoch 17/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0097\n",
      "Epoch 18/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0096\n",
      "Epoch 19/22\n",
      "40/40 [==============================] - 176s 4s/step - loss: 0.0097\n",
      "Epoch 20/22\n",
      "40/40 [==============================] - 177s 4s/step - loss: 0.0097\n",
      "Epoch 21/22\n",
      "40/40 [==============================] - 176s 4s/step - loss: 0.0096\n",
      "Epoch 22/22\n",
      "40/40 [==============================] - 176s 4s/step - loss: 0.0096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65ccf54eb8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create embedding\n",
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (224, 224, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with vgg_face_model.graph.as_default():\n",
    "        embed = vgg_face_model.predict(grayscaled_rgb_resized)\n",
    "    return embed\n",
    "\n",
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "#Generate training data\n",
    "batch_size = 50\n",
    "\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
    "        embed = create_inception_embedding(grayscaled_rgb)\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)\n",
    "\n",
    "#Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"/output\")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=22, steps_per_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Get images\n",
    "imgs = glob.glob('*.jpg')\n",
    "\n",
    "print('Found files:')\n",
    "print(imgs)\n",
    "\n",
    "\n",
    "for img in imgs:\n",
    "    pic = cv2.imread(img, cv2.IMREAD_UNCHANGED)\n",
    "    pic = cv2.resize(pic, (256, 256))\n",
    "    cv2.imwrite(img, pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/usr/local/lib/python3.6/site-packages/skimage/util/dtype.py:130: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 3 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 33 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 891 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 47 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 16 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 27 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 10 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 66 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 8 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 20 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 55 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 25 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 32 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 37 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 360 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 596 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 67 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 6 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 148 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 12 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 157 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 154 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 42 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 103 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 84 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 13 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 35 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 402 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 640 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 137 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 31 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 120 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/usr/local/lib/python3.6/site-packages/skimage/color/colorconv.py:997: UserWarning: Color data out of range: Z < 0 in 26 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "color_me = []\n",
    "for filename in os.listdir('/input/Test/'):\n",
    "    if filename != 'Thumbs.db':\n",
    "        img = img_to_array(load_img('/input/Test/'+filename))\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        color_me.append(img)\n",
    "\n",
    "\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me_embed = create_inception_embedding(color_me)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "\n",
    "# Test model\n",
    "output = model.predict([color_me, color_me_embed])\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "\tcur = np.zeros((256, 256, 3))\n",
    "\tcur[:,:,0] = color_me[i][:,:,0]\n",
    "\tcur[:,:,1:] = output[i]\n",
    "\timsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = rgb2lab(1.0/255*X)[:,:,:,0]\n",
    "X = np.array(X, dtype=float)\n",
    "X_embed = create_inception_embedding(X)\n",
    "# Test model\n",
    "output = model.predict([X, X_embed])\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "\tcur = np.zeros((256, 256, 3))\n",
    "\tcur[:,:,0] = X[i][:,:,0]\n",
    "\tcur[:,:,1:] = output[i]\n",
    "\timsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
